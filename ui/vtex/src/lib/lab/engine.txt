import { isDigit, isSymbol } from "./utils.js";
// import { box, Box } from "./aux/maybe.js";
import { tkn, Token, token } from "./token.js";
import { ASTNode } from "./nodes/abstract.node.js";
import { inf, int, nan, real } from "./nodes/number.node.js";
import { nilNode } from "./nodes/nil.node.js";
import { BinaryExpression, binex } from "./nodes/binex.node.js";
import { ErrorReport, isError, parserError, scannerError } from "./error.js";
import { falseNode, trueNode } from "./nodes/bool.node.js";
import { isSymbolNode, Sym, sym } from "./nodes/symbol.node.js";
import { call } from "./nodes/call.node.js";
import {
  dottedNumber,
  floatingPointNumber,
  integer,
  lit,
  maybe,
  some,
  word,
} from "./reader.js";
import { unary, UnaryExpression } from "./nodes/unary.node.js";
import { str } from "./nodes/string.node.js";
import { print } from "./utils.js";
import {
  Assign,
  assignment,
  isAssignmentNode,
} from "./nodes/assignment.node.js";
import { varDef, VariableDeclaration } from "./nodes/variable.node.js";
import { vector } from "./nodes/vector.node.js";
import { fnDef } from "./nodes/function.node.js";
import { Block, block } from "./nodes/block.node.js";
import { tuple } from "./nodes/tuple.node.js";
import { cond, Conditional } from "./nodes/cond.node.js";
import { loop } from "./nodes/loop.node.js";
import { Either, either, left, right } from "./aux/either.js";
import { Num } from "./nodes/number.node.js";

/**
 * Consider the expression
 *
 * ~~~
 * 1 + 2 * 3
 * ~~~
 *
 * This generates the following token stream:
 *
 * ~~~
 * [int, plus, int, star, int]
 * ~~~
 *
 * There are two possible trees we can generate fom this stream.
 * Either:
 *
 * ~~~
 *   plus
 *  /    \
 * 1     star
 *      /    \
 *     2      3
 * ~~~
 *
 * Or:
 *
 * ~~~
 *      star
 *     /    \
 *   plus    3
 *  /    \
 * 1      2
 * ~~~
 *
 * We want to avoid this ambiguity. We can resolve
 * this ambiguity through a technique called
 * _Pratt parsing_. The idea:
 *
 * 1. For any given operator `f`, there exists a value
 *    called a _binding power_, which we denote as `BP(f)`.
 * 2. Given two operators `f1` and `f2`, if `BP(f1) < BP(f2)`,
 *    then we say that _`f2` has higher precedence than `f1`_ (and
 *    conversely, that _`f1` has lower precedence than `f2`_).
 *
 * This handles the cases for the strictly-ordered relations `<` and
 * `>`. But what happens if `BP(f1) = BP(f2)`? For example, it’s
 * perfectly reasonable to write:
 * ~~~
 * 2 + 5 + 8
 * ~~~
 * For such expressions, we rely on _associativity_:
 *
 * 1. For any given operator `f`, there exists a pair of
 *    integer constants `(L,R)`. We call `L` the _left denotation_
 *    of `f`, and `R` the _right denotation_ of `f`. We denote this
 *    the pair with the notation `D(f)`.
 * 2. Given two operators `f1` and `f2`, both instances of the
 *    operator `f`, then `f2` has higher precedence than `f1` if,
 *    and only if, given `D(f) = (a, b)`, `BP(f2) + b > BP(f1) + a`.
 *
 * In short, we _nudge_ the binding powers of the operators slightly.
 * The `+` operator, for example, is left-associative, so
 * the left-hand side of the expression gets a slight-nudge (thereby
 * positioned at a lower depth in the tree). The `^` operator, in
 * contrast, is right-associative. So, whatever lies to its right
 * gets the nudge.
 *
 * @enum
 */
enum bp {
  nil,
  none,
  atom,
  assign,
  or,
  nor,
  and,
  nand,
  xor,
  xnor,
  equivalence,
  equality,
  comparison,
  sum,
  product,
  quotient,
  power,
  prefix,
  postfix,
  call,
  primary,
}

const star = (t: Token) => t.clone("*", tkn.star);

const SYMBOL = "SYMBOL";
const NUMBER = "NUMBER";
const ATOM = "ATOM";
const INFIX = "INFIX";
const PREFIX = "PREFIX";
const POSTFIX = "POSTFIX";
const GROUP = "GROUP";
const BLOCK = "BLOCK";
const ARRAY = "ARRAY";
const __ = null;

type ParsedNode = Either<ErrorReport, ASTNode>;

type Parser =
  | typeof __
  | typeof ATOM
  | typeof GROUP
  | typeof SYMBOL
  | typeof BLOCK
  | typeof ARRAY
  | typeof NUMBER
  | typeof PREFIX
  | typeof POSTFIX
  | typeof INFIX;
type ParseRule = Parser | null;
type ParserRecord = Record<tkn, [ParseRule, ParseRule, bp]>;
const NONE = bp.nil;


const ParseRules: ParserRecord = {
  [tkn.string]: [ATOM, __, bp.atom],
  [tkn.symbol]: [SYMBOL, __, bp.atom],
  [tkn.and]: [__, INFIX, bp.and],
  [tkn.or]: [__, INFIX, bp.or],
  [tkn.nand]: [__, INFIX, bp.nand],
  [tkn.nor]: [__, INFIX, bp.nor],
  [tkn.xor]: [__, INFIX, bp.xor],
  [tkn.xnor]: [__, INFIX, bp.xnor],
  [tkn.not]: [PREFIX, __, bp.prefix],
  [tkn.is]: [__, INFIX, bp.equivalence],
  [tkn.return]: [__, __, bp.nil],
  [tkn.this]: [__, __, NONE],
  [tkn.let]: [__, __, NONE],
  [tkn.def]: [__, __, NONE],
  [tkn.while]: [__, __, NONE],
  [tkn.true]: [ATOM, __, bp.atom],
  [tkn.false]: [ATOM, __, bp.atom],
  [tkn.NaN]: [NUMBER, __, bp.atom],
  [tkn.Inf]: [NUMBER, __, bp.atom],
  [tkn.do]: [__, __, NONE],
  [tkn.rem]: [__, INFIX, bp.quotient],
  [tkn.mod]: [__, INFIX, bp.quotient],
  [tkn.div]: [__, INFIX, bp.quotient],
  [tkn.class]: [__, __, NONE],
  [tkn.if]: [__, __, NONE],
  [tkn.else]: [__, __, NONE],
  [tkn.for]: [__, __, NONE],
  [tkn.null]: [ATOM, __, bp.atom],
  [tkn.end]: [__, __, NONE],
  [tkn.error]: [__, __, NONE],
  [tkn.none]: [__, __, NONE],
  [tkn.left_paren]: [GROUP, __, bp.none],
  [tkn.right_paren]: [__, __, bp.nil],
  [tkn.left_bracket]: [ARRAY, __, bp.atom],
  [tkn.right_bracket]: [__, __, bp.nil],
  [tkn.left_brace]: [BLOCK, __, bp.nil],
  [tkn.right_brace]: [__, __, bp.nil],
  [tkn.vbar]: [__, __, bp.nil],
  [tkn.semicolon]: [__, __, NONE],
  [tkn.comma]: [__, __, NONE],
  [tkn.dot]: [__, __, bp.nil],
  [tkn.plus]: [PREFIX, INFIX, bp.sum],
  [tkn.minus]: [PREFIX, INFIX, bp.sum],
  [tkn.bang]: [__, POSTFIX, bp.postfix],
  [tkn.star]: [__, INFIX, bp.product],
  [tkn.slash]: [__, INFIX, bp.product],
  [tkn.caret]: [__, INFIX, bp.power],
  [tkn.percent]: [__, INFIX, bp.product],
  [tkn.eq]: [__, __, bp.nil],
  [tkn.deq]: [__, INFIX, bp.equality],
  [tkn.neq]: [__, INFIX, bp.equality],
  [tkn.lt]: [__, INFIX, bp.comparison],
  [tkn.leq]: [__, INFIX, bp.comparison],
  [tkn.gt]: [__, INFIX, bp.comparison],
  [tkn.geq]: [__, INFIX, bp.comparison],
  [tkn.int]: [NUMBER, __, bp.atom],
  [tkn.float]: [NUMBER, __, bp.atom],
  [tkn.scinum]: [NUMBER, __, bp.atom],
  [tkn.call]: [__, __, bp.call],
  [tkn.const]: [__, __, NONE],
};

/**
 * Returns the token corresponding
 * to the given symbol.
 *
 * @param lexeme - The lexeme to tokenize.
 */
const entypeSymbol = (lexeme: string) => {
  // deno-fmt-ignore
  switch (lexeme) {
      case "and": return tkn.and;
      case "or": return tkn.or;
      case "nand": return tkn.nand;
      case "nor": return tkn.nor;
      case "xor": return tkn.xor;
      case "xnor": return tkn.xnor;
      case "not": return tkn.not;
      case "is": return tkn.is;
      case "return": return tkn.return;
      case "this": return tkn.this;
      case "let": return tkn.let;
      case "const": return tkn.const;
      case "def": return tkn.def;
      case "while": return tkn.while;
      case "true": return tkn.true;
      case "false": return tkn.false;
      case "NaN": return tkn.NaN;
      case "Inf": return tkn.Inf;
      case "do": return tkn.do;
      case "rem": return tkn.rem;
      case "mod": return tkn.mod;
      case "div": return tkn.div;
      case "class": return tkn.class;
      case "if": return tkn.if;
      case "else": return tkn.else;
      case "for": return tkn.for;
      case "null": return tkn.null;
      default: return tkn.symbol;
    }
};

const parsenum = (t: Token): ParsedNode => {
  switch (t.type) {
    case tkn.Inf:
      return right(inf);
    case tkn.NaN:
      return right(nan);
    case tkn.int:
      return right(int(t.lexeme));
    case tkn.float:
      return right(real(t.lexeme));
    default:
      return left(parserError("Expected number", t));
  }
};

/**
 * Returns the prefix parser from the
 * {@link parseRules}.
 */
const prefixRule = (tokenType: tkn) => ParseRules[tokenType][0];

/**
 * Returns the infix parser from the
 * {@link parseRules}.
 */
const infixRule = (tokenType: tkn) => ParseRules[tokenType][1];

/**
 * Returns the precedence of the given token type.
 */
const precedenceOf = (tokenType: tkn) => ParseRules[tokenType][2];

const atom = (token: Token): ParsedNode => {
  const lexeme = token.lexeme;
  // deno-fmt-ignore
  switch (token.type) {
    case tkn.string:
      return right(str(lexeme));
    case tkn.null:
      return right(nilNode);
    case tkn.false:
      return right(falseNode);
    case tkn.true:
      return right(trueNode);
    default:
      return left(parserError("Expected atom", token));
  }
};

/**
 * This token is used purely to ensure
 * the {@link Engine.RecentToken} and
 * {@link Engine.PreviousToken} fields
 * always have some token initialized.
 */
const initialToken = token(tkn.none, "");

export class Engine {
  /**
   * The `RecentToken` property
   * maps to the token the Engine
   * last scanned.
   */
  private RecentToken: Token;

  /**
   * Strings to tokenize, parse,
   * or evaluate are always stored
   * in the `InputString` field.
   */
  private Input: string;

  /**
   * The `StartIndex` maps to
   * the character index of
   * the current lexeme.
   */
  private StartIndex: number;

  /**
   * The `CurrentIndex` maps to
   * the {@link Engine.Input} index
   * the engine’s scanner is currently
   * on.
   */
  private CurrentIndex: number;

  /**
   * The `Line` property
   * maps to a line number in
   * {@link Engine.Input}. Specifically,
   * the line where the
   * {@link Engine.RecentToken} was
   * generated.
   */
  private Line: number;

  /**
   * The `Column` property maps
   * to the column the
   * {@link Engine.RecentToken}
   * was generated.
   */
  private Column: number;

  /**
   * Records the node parsed
   * just before {@link Engine.recentNode}.
   */
  private LastNode: ParsedNode;

  /**
   * The `Error` property maps to either `null`
   * or an {@link ErrorReport}. If an error occurs
   * during the scanning or parsing stage, this
   * field will be initialized.
   *
   * __References__.
   * 1. _See also_ {@link Engine.syntaxError} (the method
   *   called for errors during parsing).
   */
  private Error: ErrorReport | null;

  // § Engine Constructor ============================================
  constructor() {
    this.Input = "";
    this.LastNode = right(nilNode);
    this.RecentToken = initialToken;
    this.StartIndex = 0;
    this.CurrentIndex = 0;
    this.Column = 0;
    this.Line = 0;
    this.Error = null;
    this.peek = initialToken;
    this.currentToken = initialToken;
  }

  /**
   * Initializes the Engine’s state.
   * This method should always be called
   * before invoking, and before returning
   * from, the following methods:
   *
   * 1. {@link Engine.tokenize}
   * 2. {@link Engine.parse}
   * 3. {@link Engine.evaluate}
   */
  private init(src: string) {
    this.Input = src;
    this.LastNode = right(nilNode);
    this.RecentToken = initialToken;
    this.StartIndex = 0;
    this.CurrentIndex = 0;
    this.Column = 0;
    this.Line = 0;
    this.Error = null;
  }

  /**
   * Returns true if the Engine has
   * no more characters to scan.
   */
  private atEnd() {
    return (
      this.CurrentIndex >= this.Input.length ||
      this.Error !== null
    );
  }

  /**
   * Returns true if the Engine is
   * in the OK state and false otherwise.
   *
   * __References__.
   * 1. _See also_ {@link Engine.State} (providing
   *   a broader description of the Engine’s state).
   */
  private isSafe() {
    return this.Error === null;
  }

  /**
   * The `lexeme` method returns a slice
   * of the current {@link Engine.Input},
   * based on {@link Engine.StartIndex} and
   * {@link Engine.CurrentIndex}.
   */
  private lexeme() {
    return this.Input.slice(
      this.StartIndex,
      this.CurrentIndex,
    );
  }

  /**
   * Creates a new {@link Token}. We use
   * a separate method for token creation
   * to ensure every token generated has
   * a line number and a column.
   *
   * @param type - The token’s defined type.
   * @param lexeme - The token’s given lexeme.
   * @returns A new Token.
   *
   * __References__.
   * 1. For token type definitions, _see_ {@link tkn}.
   * 2. _See also_ {@link token} (implementing the Token
   * factory function used).
   */
  private newToken(type: tkn, lexeme?: string) {
    const line = this.Line;
    const column = this.Column;
    lexeme = lexeme ? lexeme : this.lexeme();
    const out = token(type, lexeme, line, column);
    this.RecentToken = out;
    return out;
  }

  /**
   * Generates a lexical error and initializes
   * the {@link Engine.Error} field.
   * If this method is called, the engine will cease
   * all further operations.
   */
  private lexicalError(message: string) {
    const out = this.newToken(tkn.error, message);
    this.Error = scannerError(message, out);
    return out;
  }

  /**
   * Returns the next character within
   * {@link Engine.Input}, given the
   * {@link Engine.CurrentIndex}.
   *
   * __References__.
   * 1. _See also_ {@link Engine.getNextToken} (the
   * predominant user of this method).
   */
  private getChar() {
    this.Column++;
    return this.Input[this.CurrentIndex++];
  }

  /**
   * Returns the character at
   * {@link Engine.CurrentIndex}, _without_
   * consuming the character.
   */
  private peekChar() {
    return this.Input[this.CurrentIndex];
  }

  /**
   * Returns the character at one more than the
   * {@link Engine.CurrentIndex}, _without_
   * consuming the character.
   */
  private peekNextChar() {
    if (this.CurrentIndex + 1 >= this.Input.length) {
      return "";
    }
    return this.Input[this.CurrentIndex + 1];
  }

  /**
   * The `tick` method is used to increment both
   * the {@link Engine.Column} and
   * {@link Engine.CurrentIndex} (scanner methods
   * should never directly mutate these properties).
   * Parsing methods should never call this method.
   */
  private tick() {
    this.Column++;
    this.CurrentIndex++;
  }

  /**
   * Continously moves {@link Engine.CurrentIndex}
   * forward at every whitespace character.
   * This has the effect of skipping such
   * characters.
   */
  private skipWhitespace() {
    while (this.canLoop()) {
      const c = this.peekChar();
      if (this.Error !== null) break;
      switch (c) {
        case " ":
        case "\t":
          this.tick();
          break;
        case "\r":
        case "\n":
          this.tick();
          this.Line++;
          this.Column = 0;
          break;
        default:
          return;
      }
    }
  }

  /**
   * Given the `char` argument,
   * increments {@link Engine.CurrentIndex}
   * if the given character matches, and returns
   * true. Otherwise, returns false without
   * an increment.
   */
  private match(char: string) {
    if (this.atEnd()) return false;
    if (this.Input[this.CurrentIndex] !== char) {
      return false;
    }
    this.tick();
    return true;
  }

  /**
   * Scans for keywords and identifiers.
   */
  private scanSymbol() {
    const engine = this;
    while (
      engine.canLoop() &&
      (isSymbol(engine.peekChar()) ||
        isDigit(engine.peekChar()))
    ) {
      engine.tick();
      if (engine.atEnd()) {
        break;
      }
    }
    const text = engine.Input.slice(
      engine.StartIndex,
      engine.CurrentIndex,
    );
    const symbolTokenType = entypeSymbol(text);
    return engine.newToken(symbolTokenType);
  }

  /**
   * Returns the next token from the
   * {@link Engine.Input}.
   */
  private scanNextToken() {
    if (this.Error) return this.newToken(tkn.end, "END");
    this.skipWhitespace();

    if (this.atEnd()) {
      return this.newToken(tkn.end, "END");
    }

    this.StartIndex = this.CurrentIndex;

    if (isSymbol(this.peekChar())) {
      return this.scanSymbol();
    }

    if (isDigit(this.peekChar())) {
      return this.scanNumber();
    }

    const char = this.getChar();
    const peek = this.peekChar();

    if (char === "." && isDigit(peek)) {
      return this.scanNumber(tkn.float);
    }

    let type = tkn.error;

    // deno-fmt-ignore
    switch (char) {
      case "(": type = tkn.left_paren; break;
      case ")": type = tkn.right_paren; break;
      case "[": type = tkn.left_bracket; break;
      case "]": type = tkn.right_bracket; break;
      case "{": type = tkn.left_brace; break;
      case "}": type = tkn.right_brace; break;
      case ",": type = tkn.comma; break;
      case "-": type = tkn.minus; break;
      case ".": type = tkn.dot; break;
      case "+": type = tkn.plus; break;
      case "^": type = tkn.caret; break;
      case ";": type = tkn.semicolon; break;
      case "*": type = tkn.star; break;
      case "%": type = tkn.percent; break;
      case "|": type = tkn.vbar; break;
      case "/": type = tkn.slash; break;
      case "!": type = this.match("=") ? tkn.neq : tkn.bang; break;
      case "=": type = this.match("=") ? tkn.deq : tkn.eq; break;
      case "<": type = this.match("=") ? tkn.leq : tkn.lt; break;
      case ">": type = this.match("=") ? tkn.geq : tkn.gt; break;
      case '"': return this.scanStringLiteral();
    }
    return type === tkn.error
      ? this.lexicalError(`Unrecognized token: [${char}]`)
      : this.newToken(type);
  }

  /**
   * Scans a string value. Strings always
   * start with an opening `"` (double quote) and
   * end with a closing `"`.
   *
   * __References__.
   * 1. See {@link Engine.getNextToken} (containing
   *    the triggering case for calling this method).
   */
  private scanStringLiteral() {
    const engine = this;
    while (engine.peekChar() !== `"` && engine.canLoop()) {
      engine.tick();
      if (engine.peekChar() === `\n`) {
        engine.Line++;
        engine.Column = 0;
      }
    }
    if (engine.atEnd()) {
      return engine.lexicalError("Unterminated string.");
    }
    engine.tick();
    const lexeme = this.Input.slice(
      engine.StartIndex + 1,
      engine.CurrentIndex - 1,
    );
    return engine.newToken(tkn.string, lexeme);
  }

  /**
   * The `canLoop` method is the primary
   * guard for most loops within the engine.
   * It returns false if the engine is no longer
   * in the ok state or if the engine has reached
   * the end of input (prematurely or otherwise).
   * Else, returns true.
   */
  private canLoop() {
    return !this.atEnd() && this.isSafe();
  }

  /**
   * Scans for a number token.
   * Numbers are goverened by the following
   * premises.
   *
   * Digit-separated numbers are recognized.
   *
   * E.g., `132_122`, or `2_854.321_553`.
   * If a separator is used (the character `_`),
   * it must always be followed by either:
   *
   * 1. Three digits (the digitGroupSize), or
   * 2. A dot followed by three digits
   *
   * @param type - The initial numeric token type.
   * The scanner method allows setting this type
   * because we allow dotted numbers.
   */
  private scanNumber(type: tkn = tkn.int) {
    const engine = this;
    let hasSeparators = false;
    while (engine.canLoop() && isDigit(this.peekChar())) {
      engine.tick();

      // If the current character is a digit and the
      // the next character is the separator `_`,
      // then this is a separated number.
      if (
        this.peekChar() === "_" &&
        isDigit(this.peekNextChar())
      ) {
        const digitGroupSize = 3;
        let digitCount = 0;
        while (
          digitCount < digitGroupSize &&
          this.canLoop()
        ) {
          engine.tick();
          digitCount++;
        }

        // If we don’t get three digits following
        // the `_`, then this is not a valid
        // digit group.
        if (digitCount !== digitGroupSize) {
          const msg = `Invalid separated number.`;
          return engine.lexicalError(msg);
        }
        hasSeparators = true;
      }

      // If the current character is a dot
      // and the next character is a digit,
      // then this a floating point number.
      if (
        engine.peekChar() === "." &&
        isDigit(engine.peekNextChar())
      ) {
        type = tkn.float; // change the output token type
        engine.tick();

        // We continue incrementing so long as we see digits.
        // This consumes the digits following the `.`
        while (
          isDigit(engine.peekChar()) &&
          this.canLoop()
        ) {
          engine.tick();
        }
      }

      // If the current character is an `E`, then
      if (engine.peekChar() === "E") {
        engine.tick();
        if (
          engine.peekChar() === "+" || // allow leading '+'
          engine.peekChar() === "-" || // allow leading '-'
          isDigit(engine.peekNextChar()) // but only integer powers
        ) {
          type = tkn.scinum;
          engine.tick();
          while (
            isDigit(engine.peekChar()) &&
            this.canLoop()
          ) {
            engine.tick();
          }
        } else {
          return engine.lexicalError(
            "Invalid scientific number.",
          );
        }
      }
    }
    // replace the thousands separators to ensure correct
    // number cast in parser
    let lexeme = this.lexeme();
    if (hasSeparators) {
      lexeme = lexeme.replaceAll("_", "");
    }
    return engine.newToken(type, lexeme);
  }

  /**
   * Tokenizes the given input string.
   * This method is used primarily for testing,
   * and isn’t directly used by the Engine
   * substantively. It is exposed in the public API
   * as a debugging tool.
   *
   * @param text
   * The input text to tokenize.
   *
   * @param fn
   * An optional callback that takes a Token and
   * returns some type X. The return type
   * of the callback will be pushed to the
   * output array. Defaults to the token scanned.
   *
   * __References__.
   * 1. _See_ {@link Token} (defining _Token_).
   */
  public tokenize<X = Token>(
    text: string,
    fn?: (t: Token) => X,
  ) {
    this.init(text);
    const output: X[] = [];
    while (this.canLoop()) {
      const token = this.scanNextToken();
      output.push((fn ? fn(token) : token) as unknown as X);
    }
    return output;
  }

  // § Parser Utilities
  peek: Token;
  currentToken: Token;
  advance() {
    const token = this.peek;
    this.currentToken = token;
    this.peek = this.scanNextToken();
    return token;
  }

  matches(tokentype: tkn) {
    if (this.peek.type === tokentype) {
      this.advance();
      return true;
    }
    return false;
  }
  check(tokentype: tkn) {
    return this.peek && this.peek.type === tokentype;
  }
  implicitSemicolon() {
    const current = this.currentToken;
    const peek = this.peek;
    return (
      peek.isEOF() ||
      peek.is(tkn.right_brace) ||
      current.is(tkn.right_brace)
    );
  }

  // § Parser
  parse(text: string) {
    this.init(text);
    this.advance();
    return this.PROG();
  }

  PROG() {
    let result: ASTNode[] = [];
    while (this.canLoop()) {
      const node = this.STATEMENT();
      if (node.isLeft()) return node.unwrap();
      result.push(node.unwrap());
    }
    return result;
  }

  STATEMENT() {
    switch (this.peek.type) {
      // deno-fmt-ignore
      case tkn.left_brace: return this.BLOCK();
      case tkn.while:
        return this.WHILE();
      case tkn.if:
        return this.IFELSE();
      case tkn.let:
        return this.VAR();
      default:
        return this.EXPR();
    }
  }

  BLOCK(): Either<ErrorReport, Block> {
    const engine = this;
    engine.advance(); // eat the '{'
    const statements: ASTNode[] = [];
    while (
      engine.peek.type !== tkn.right_brace &&
      engine.canLoop()
    ) {
      const node = engine.STATEMENT();
      engine.advance();
      if (node.isLeft()) return node;
      if (node.isRight()) statements.push(node.unwrap());
    }
    return engine
      .advance()
      .map((token) =>
        token.is(tkn.right_brace)
          ? right(block(statements))
          : engine.parseError(`Expected closing '}'`, token)
      );
  }

  IFELSE(): Either<ErrorReport, Conditional> {
    this.advance(); // eat the 'if'
    const engine = this;
    const C = engine.exp(bp.nil);
    const ifBlock = engine.BLOCK();
    const elseBlock = engine.matches(tkn.else)
      ? engine.STATEMENT()
      : right(nilNode);
    return C.map((c) =>
      cond(c, ifBlock.read(nilNode), elseBlock.read(nilNode))
    );
  }

  parseError(message: string, token?: Token) {
    const engine = this;
    const error = parserError(
      message,
      token ? token : engine.currentToken,
    );
    return left(error);
  }

  WHILE() {
    const engine = this;
    engine.advance();
    const condition = engine.exp(bp.nil);
    const body = engine.BLOCK();
    return condition.map((c) => loop(c, body.read(nilNode)));
  }

  VAR(): Either<ErrorReport, VariableDeclaration> {
    const engine = this;
    engine.advance();
    return engine
      .exp()
      .chain((n) =>
        isAssignmentNode(n)
          ? right(varDef(n.symbol(), n.value()))
          : engine.parseError(`Expected valid assignment`)
      );
  }

  EXPR(): Either<ErrorReport, ASTNode> {
    const engine = this;
    return engine
      .exp()
      .chain((n) =>
        engine.implicitSemicolon() ? right(n) : engine
          .advance()
          .map((token) =>
            token.is(tkn.semicolon)
              ? right(n)
              : engine.parseError(`Expected ';'`, token)
          )
      );
  }

  SYMBOL(): Either<ErrorReport, (Assign | Sym)> {
    const engine = this;
    const token = engine.currentToken;
    const out = token.isSymbol()
      ? right(sym(engine.currentToken))
      : engine.parseError(`Expected symbol`, token);
    const assign = (n: ASTNode) => assignment(sym(token), n);
    const res = engine.check(tkn.eq)
      ? engine.advance().map(() => engine.exp().map(assign))
      : out;
    return res;
  }

  NUMBER(): Either<ErrorReport, (Num | BinaryExpression)> {
    const engine = this;
    const token = engine.currentToken;
    return parsenum(token)
      .map((lhs) =>
        engine.check(tkn.symbol)
          ? engine
            .exp()
            .map((rhs) => binex(lhs, star(token), rhs))
          : lhs
      )
      .flatten();
  }

  ATOM(): Either<ErrorReport, ASTNode> {
    const engine = this;
    return atom(engine.currentToken);
  }

  INFIX(): Either<ErrorReport, BinaryExpression> {
    const engine = this;
    const out = engine.currentToken.map((op) =>
      engine.LastNode.chain((lhs) =>
        engine.exp().map((rhs) => binex(lhs, op, rhs))
      )
    );
    return out;
  }

  PREFIX(): Either<ErrorReport, UnaryExpression> {
    const engine = this;
    return engine
      .exp()
      .map((arg) => unary(engine.currentToken, arg));
  }

  POSTFIX(): Either<ErrorReport, UnaryExpression> {
    const engine = this;
    return engine.LastNode.map(
      (arg) => unary(engine.currentToken, arg),
    );
  }

  GROUP(): Either<ErrorReport, ASTNode> {
    const engine = this;
    return engine.exp().chain((node) =>
      engine.advance().map((token) =>
        token.is(tkn.right_paren)
          ? right(node)
          : engine.parseError(`[Group]: Expected ')'`, token)
      )
    );
  }

  ARRAY() {
    const engine = this;
    return left(
      parserError("Invalid parse rule", engine.currentToken),
    );
  }

  NIL() {
    const engine = this;
    return left(
      parserError("Unexpected [NIL]", engine.currentToken),
    );
  }

  exp(minbp = bp.none): ParsedNode {
    let peek = this.advance();
    const prefix = prefixRule(peek.type);
    if (prefix === null) return this.NIL();
    let left = this[prefix]();
    this.LastNode = left;
    while (minbp < precedenceOf(this.peek.type)) {
      peek = this.advance();
      if (peek.isEOF()) break;
      const infix = infixRule(peek.type);
      if (infix === null) return left;
      const right = this[infix]();
      left = right;
      this.LastNode = left;
    }
    return left;
  }
}

const engine = new Engine();
const src = `
while k < 5 {
  let i = 10;
}
`;
// const tokens = engine.tokenize(src);
// print(tokens);
const parsing = engine.parse(src);
print(parsing);
print(parsing, "json");
